{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo Real: Regressão Logística\n",
    "\n",
    "Lembrando do modelo: dado $X \\subset R^n$, e $Y \\in \\{0, 1\\}$, queremos modelar $P(Y | X) $\n",
    "\n",
    "Ajustamos variáveis $w \\in R^n$ e $b \\in R$ em uma função $\\phi(w^T x + b)$ com $\\phi$ sendo a função logística: $\\phi(x) = \\frac{1}{1 + e^{-x}}$ de modo a aproxima-la à distribuição dos dados. \n",
    "\n",
    "Calculamos a distância da nossa função aos dados por meio de uma função de erro, como a entropia cruzada\n",
    "\n",
    "A regressão logística não tem fórmula fechada como a regressão linear, e então precisa ser aproximada iterativamente com, por exemplo, gradiente descendente, algo bem próximo do que vamos fazer depois com redes neurais\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "rng = numpy.random\n",
    "\n",
    "#Geramos um dataset aleatório\n",
    "N     = 400  # número de samples\n",
    "feats = 80  # dimensão de X\n",
    "\n",
    "reg = 0.01 \n",
    "lrate = 0.1\n",
    "train_steps = 10000\n",
    "\n",
    "D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo inicial:\n",
      "[ 1.00511392 -0.57689606  1.41667788 -0.63896681  0.02442599  1.88308126\n",
      "  0.26708231 -1.35224373  0.33745236 -1.08164057 -0.37494809  0.27911922\n",
      " -0.63412044 -1.93504213  0.30241739  0.24547618  0.3333101  -0.39827942\n",
      " -0.39572764  0.78540794 -0.12079154 -0.6304335  -1.5673144   0.95311307\n",
      " -0.58019301  0.27699765 -0.60386652 -0.16089546 -0.33377906  1.56189061\n",
      "  0.64754723  1.3102639   2.1094359   0.43391526 -0.70837611  1.33998524\n",
      "  0.32193559 -1.46285696  0.17470696 -0.84009024  0.89783436  0.94069505\n",
      "  1.4287452   1.01395093 -0.70399384 -0.17354183  0.97517412  0.00905943\n",
      " -1.25402882  0.25748479 -0.9070115   1.32655534  1.4118332  -1.52355775\n",
      "  0.83309389  1.29165229 -0.03453613 -0.18436934  0.21752453 -0.70230508\n",
      "  0.29193562  0.34958274 -0.24258097 -0.32193636 -1.03638478 -0.65307213\n",
      " -0.4749035   0.55112005 -2.33509842 -0.27948956 -0.76870945  1.06865385\n",
      "  1.36955472  0.23340198  1.13320014  0.82380872  0.67688965 -0.59377532\n",
      "  0.67489563  0.16517978]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Declaramos as variáveis do nosso modelo\n",
    "w = theano.shared(rng.randn(feats), name='w')\n",
    "b = theano.shared(0., name='b')\n",
    "\n",
    "print(\"Modelo inicial:\")\n",
    "print(w.get_value())\n",
    "print(b.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declaramos as entradas e construímos o grafo\n",
    "x = T.dmatrix('x')\n",
    "y = T.dvector('y')\n",
    "\n",
    "#grafo de computação\n",
    "prob = 1 / (1 + T.exp(-T.dot(x, w) - b)) #funcao logistica \n",
    "xent = -y * T.log(prob) - (1-y) * T.log(1-prob)  #entropia cruzada como funcao de erro\n",
    "cost = xent.mean() + reg * (w ** 2).sum() #função de custo com regularização\n",
    "\n",
    "#gradientes que precisamos para atualizar\n",
    "gw = T.grad(cost, w) \n",
    "gb = T.grad(cost, b)\n",
    "\n",
    "pred = prob > 0.5 #classificação final\n",
    "\n",
    "train = theano.function(\n",
    "            inputs =[x,y],\n",
    "            outputs=[cost],\n",
    "            updates =((w, w - lrate * gw), (b, b - lrate * gb))\n",
    ")\n",
    "predict = theano.function(inputs=[x], outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "[ 0.2352585   0.05271406  0.0843816   0.10636819  0.09777833  0.11056372\n",
      " -0.13924167  0.03658262  0.03088404 -0.17202137 -0.00197768 -0.23786841\n",
      "  0.08404153  0.01693306 -0.02586031  0.13434174  0.00503928  0.12976716\n",
      "  0.00726391 -0.16474577  0.00993384 -0.17290333  0.12692331  0.18377344\n",
      " -0.02534364 -0.0309019   0.02290344 -0.01197623 -0.08396446 -0.09888248\n",
      "  0.08702242  0.16960937  0.11459188  0.24938748  0.02360551 -0.0669684\n",
      " -0.01088191  0.05708302  0.01405858 -0.00949977 -0.11928919 -0.08322107\n",
      "  0.21922813  0.15327323  0.13301169 -0.01100598  0.187169    0.18598729\n",
      " -0.31410631  0.00174422  0.15419301 -0.08304781  0.14571943  0.00391978\n",
      "  0.07481458 -0.13329394 -0.03929186 -0.00855504  0.24578408 -0.13181403\n",
      " -0.05334212 -0.12521717 -0.07812063 -0.00387871  0.22195901 -0.07407684\n",
      "  0.21572049 -0.23840053  0.12834404 -0.10668704 -0.08806761  0.28870504\n",
      " -0.08108954  0.11625554 -0.00861516 -0.03074065  0.0924149   0.02623087\n",
      " -0.12662554  0.01133747]\n",
      "-0.001227776603438725\n"
     ]
    }
   ],
   "source": [
    "#Treinamos \n",
    "for i in range(train_steps):\n",
    "    err = train(D[0], D[1])\n",
    "    \n",
    "#Verificamos\n",
    "score = np.mean(predict(D[0]) == D[1])\n",
    "print(score)\n",
    "\n",
    "#Vemos nossos pesos se estivermos interessados neles\n",
    "print(w.get_value())\n",
    "print(b.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
